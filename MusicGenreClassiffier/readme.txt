In recent years, streaming services with huge catalogs have become the primary medium through which most people listen to their favorite music. But at the same time, the sheer amount of music on offer can mean that users can get a bit overwhelmed when trying to find newer music that suits their tastes.

For this reason, streaming services have looked for ways to categorize music to allow for personalized recommendations. One method involves direct analysis of the raw audio information in a given song, scoring the raw data on a variety of metrics. In this project, I will examine data compiled by a research group known as The Echo Nest. The goal is to examine this dataset and classify the songs as 'Hip-Hop' or 'Rock', all without listening to a single one. In doing so, we will practice how to clean data, do exploratory data visualization, and use function reduction for the goal of feeding our data through some simple machine learning algorithms such as decision trees and logistic regression.
